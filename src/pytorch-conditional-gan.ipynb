{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "078572cd26bfb8a809b4464ba675fdb3cd418fa7",
        "id": "3iFXZP1Cq9zq"
      },
      "source": [
        "## PyTorch Conditional GAN\n",
        "\n",
        "This kernel is a PyTorch implementation of [Conditional GAN](https://arxiv.org/abs/1411.1784), which is a GAN that allows you to choose the label of the generated image. The generator and the discriminator are going to be simple feedforward networks, so I guess the smiles won't be as good as in this [nice kernel](https://www.kaggle.com/sgamez/fashion-ac-gan-with-keras) by [Sergio Gámez](https://www.kaggle.com/sgamez). I used [this implementation](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py) by [eriklindernoren](https://github.com/eriklindernoren) as inspiration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "id": "wlU5CQdoq9zv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from numpy import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vuWfoa6W3wrg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GodFgWF_8s3O"
      },
      "outputs": [],
      "source": [
        "class smiles_coder:\n",
        "    def __init__(self):\n",
        "        self.char_set = set([' '])\n",
        "        self.char_to_int = None\n",
        "        self.int_to_char = None\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, smiles_data, max_length = 150):\n",
        "        for i in tqdm(range(len(smiles_data))):\n",
        "            smiles_data[i] = smiles_data[i].ljust(max_length)\n",
        "            self.char_set = self.char_set.union(set(smiles_data[i]))\n",
        "        self.max_length = max_length\n",
        "        self.n_class = len(self.char_set)\n",
        "        self.char_to_int = dict((c, i) for i, c in enumerate(self.char_set))\n",
        "        self.int_to_char = dict((i, c) for i, c in enumerate(self.char_set))\n",
        "        self.fitted = True\n",
        "\n",
        "    def transform(self, smiles_data):\n",
        "        if not self.fitted:\n",
        "            raise ValueError('smiles coder is not fitted')\n",
        "        m = []\n",
        "        for i in tqdm(range(len(smiles_data))):\n",
        "            smiles_data[i] = smiles_data[i].ljust(self.max_length)\n",
        "            chars = smiles_data[i]\n",
        "            l = np.zeros((self.max_length, self.n_class))\n",
        "            for t, char in enumerate(chars):\n",
        "                if t >= self.max_length:\n",
        "                    break\n",
        "                else:\n",
        "                    if char in self.char_set:\n",
        "                        l[t, self.char_to_int[char]] = 1\n",
        "            m.append(l)\n",
        "        return np.array(m)\n",
        "\n",
        "    def label(self, smiles_data):\n",
        "        if not self.fitted:\n",
        "            raise ValueError('smiles coder is not fitted')\n",
        "        m = []\n",
        "        for i in tqdm(range(len(smiles_data))):\n",
        "            smiles_data[i] = smiles_data[i].ljust(self.max_length)\n",
        "            chars = smiles_data[i]\n",
        "            l = np.zeros((self.max_length, 1))\n",
        "            for t, char in enumerate(chars):\n",
        "                if t >= self.max_length:\n",
        "                    break\n",
        "                else:\n",
        "                    if char in self.char_set:\n",
        "                        l[t, 0] = self.char_to_int[char]\n",
        "            m.append(l)\n",
        "        return np.array(m)\n",
        "\n",
        "    def inverse_transform(self, m):\n",
        "        if not self.fitted:\n",
        "            raise ValueError('smiles coder is not fitted')\n",
        "        smiles_out = []\n",
        "        for l in m:\n",
        "            ll = np.argmax(l, axis=1)\n",
        "            string = ''\n",
        "            for t in ll:\n",
        "                if self.int_to_char[t] == ' ':\n",
        "                    continue\n",
        "                string += self.int_to_char[t]\n",
        "            smiles_out.append(string)\n",
        "        return np.array(smiles_out)\n",
        "\n",
        "    def inverse_label(self, l):\n",
        "        if not self.fitted:\n",
        "            raise ValueError('smiles coder is not fitted')\n",
        "        smiles_out = []\n",
        "        for ll in l:\n",
        "            string = ''\n",
        "            for t in ll:\n",
        "                if self.int_to_char[t] == ' ':\n",
        "                    continue\n",
        "                string += self.int_to_char[t]\n",
        "            smiles_out.append(string)\n",
        "        return np.array(smiles_out)\n",
        "\n",
        "    def int_to_char(self):\n",
        "        return self.int_to_char\n",
        "\n",
        "    def char_to_int(self):\n",
        "        return self.char_to_int\n",
        "\n",
        "    def save(self, save_path):\n",
        "        np.savez(save_path, char_set = self.char_set, char_to_int=self.char_to_int, int_to_char=self.int_to_char,\n",
        "                            max_length = self.max_length, n_class = len(self.char_set))\n",
        "\n",
        "    def load(self, save_path):\n",
        "        saved = np.load(save_path, allow_pickle=True)\n",
        "        self.char_set = saved['char_set'].tolist()\n",
        "        self.char_to_int = saved['char_to_int'].tolist()\n",
        "        self.int_to_char = saved['int_to_char'].tolist()\n",
        "        self.max_length = saved['max_length'].tolist()\n",
        "        self.n_class = len(self.char_set)\n",
        "        self.fitted = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "75fac5f0577eb3e3e1ee914f7118a0fdd0207951",
        "id": "oP26SY6Uq9zx"
      },
      "source": [
        " Let's start by defining a Dataset class:\n",
        "* [Data Loading and Processing Tutorial on PyTorch's documentation](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
        "* [torchvision](https://github.com/pytorch/vision) has a [built-in class for Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ve9IM4iEq9zy"
      },
      "outputs": [],
      "source": [
        "replace_dict = {'Ag':'D', 'Al':'E', 'Ar':'G', 'As':'J', 'Au':'Q', 'Ba':'X', 'Be':'Y',\n",
        "                'Br':'f', 'Ca':'h', 'Cd':'j', 'Ce':'k', 'Cl':'m', 'Cn':'p', 'Co':'q',\n",
        "                'Cr':'v', 'Cu':'w', 'Fe':'x', 'Hg':'y', 'Ir':'z', 'La':'!', 'Mg':'$',\n",
        "                'Mn':'¬', 'Mo':'&', 'Na':'_', 'Ni':'£', 'Pb':'¢', 'Pt':'?', 'Ra':'ª',\n",
        "                'Ru':'º', 'Sb':';', 'Sc':':', 'Se':'>', 'Si':'<', 'Sn':'§', 'Sr':'~',\n",
        "                'Te':'^', 'Tl':'|', 'Zn':'{', '@@':'}'}\n",
        "\n",
        "inverse_dict = {v: k for k, v in replace_dict.items()}\n",
        "\n",
        "def preprocessing_data(molecules, replacement):\n",
        "    molecules = pd.Series(molecules)\n",
        "\n",
        "    for pattern, repl in replacement.items():\n",
        "        molecules = molecules.str.replace(pattern, repl, regex=False)\n",
        "\n",
        "    return molecules\n",
        "\n",
        "def get_hot_smiles(file_name):\n",
        "    with open(file_name, \"r\") as f:\n",
        "        smiles = [i.strip().split(' ') for i in f.readlines()]\n",
        "        f.close()\n",
        "\n",
        "    # DEFINING THE CLASSES DATAFRAME\n",
        "    classes = []\n",
        "    for s in smiles:\n",
        "        classes.append(s[1].split(\"@\"))\n",
        "\n",
        "    unique_elements = list(set([item for sublist in classes for item in sublist]))\n",
        "\n",
        "    classes_df = pd.DataFrame(columns=unique_elements)\n",
        "\n",
        "    data = []\n",
        "    for item in classes:\n",
        "        row = {element: float(1) if element in item else float(0) for element in unique_elements}\n",
        "        data.append(row)\n",
        "\n",
        "    classes_df = pd.concat([classes_df, pd.DataFrame(data)], ignore_index=True)\n",
        "\n",
        "    classes_hot_arrays = classes_df.values\n",
        "\n",
        "    molecules = []\n",
        "    for s in smiles:\n",
        "        molecules.append(s[0])\n",
        "\n",
        "    processed_molecules = preprocessing_data(molecules, replace_dict)\n",
        "\n",
        "    coder = smiles_coder()\n",
        "    coder.fit(processed_molecules)\n",
        "    smiles_hot_arrays = coder.transform(processed_molecules)\n",
        "\n",
        "    return smiles_hot_arrays, molecules, classes_hot_arrays, coder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "_uuid": "e4b8af03f05931d7d0ee171ec9d28701baaab122",
        "collapsed": true,
        "id": "fKJ7QANxq9zy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DrugLikeMolecules(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.transform = transform\n",
        "        self.smiles, self.dataset, self.labels, self.coder = get_hot_smiles(\"chebi_smiles_1of10_subset.txt\")\n",
        "\n",
        "        self.smiles_nodes = self.smiles.shape[1] * self.smiles.shape[2]\n",
        "        self.classes_nodes = self.labels.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        sml = self.smiles[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            sml = self.transform(sml)\n",
        "\n",
        "        return sml, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_uuid": "c2b45eafe82ac480f57896c8406176d22bbeea89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dVuvqlP6q9zz",
        "outputId": "08550428-fcc3-4b3f-a191-05af00484de0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3689/3689 [00:00<00:00, 29417.79it/s]\n",
            "100%|██████████| 3689/3689 [00:00<00:00, 5608.21it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = DrugLikeMolecules()\n",
        "dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_uuid": "c7a3b05bb018357a2e595d523d80a770e6a20c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MhkP5zkOq9z1",
        "outputId": "27fd40cd-1d22-4af5-a6cf-04135aa19dfe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3689/3689 [00:00<00:00, 35617.77it/s]\n",
            "100%|██████████| 3689/3689 [00:00<00:00, 6757.30it/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "dataset = DrugLikeMolecules(transform=transform)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ccef848d8bd24db1c12e5fec03cdafcf27468a59",
        "id": "vsk8JiBJq9z1"
      },
      "source": [
        "Now let's define the generator and the discriminator, which are simple MLPs. I'm going to use an embedding layer for the label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_uuid": "83a994dc0acddf5d2a2ed1b706b88f6e308997dd",
        "collapsed": true,
        "id": "MO1NK-svq9z2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, smiles_nodes, classes_nodes, smiles_shape):\n",
        "        super().__init__()\n",
        "        self.smiles_nodes = smiles_nodes\n",
        "        self.classes_nodes = classes_nodes\n",
        "        self.smiles_shape = smiles_shape\n",
        "\n",
        "        self.label_emb = nn.Embedding(self.classes_nodes, self.classes_nodes)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(smiles_nodes + (classes_nodes**2), 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "      x = x.view(x.size(0), self.smiles_nodes)\n",
        "      c = self.label_emb(labels)\n",
        "      c = c.view(c.size(0), -1)\n",
        "      print(f\"X shape: {x.shape} / C shape: {c.shape}\")\n",
        "      x = torch.cat([x, c], 1)\n",
        "      out = self.model(x)\n",
        "      return out.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "_uuid": "cf8e8720990e3dbd63bc074b340d15ffc15ddd17",
        "collapsed": true,
        "id": "Fp0tOuNvq9z2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, smiles_nodes, classes_nodes, smiles_shape):\n",
        "        super().__init__()\n",
        "        self.smiles_nodes = smiles_nodes\n",
        "        self.classes_nodes = classes_nodes\n",
        "        self.smiles_shape = smiles_shape\n",
        "\n",
        "        self.label_emb = nn.Embedding(self.classes_nodes, self.classes_nodes)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100 + classes_nodes**2, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, smiles_nodes),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = z.view(z.size(0), 100)\n",
        "        c = self.label_emb(labels)\n",
        "        c = c.view(c.size(0), -1)\n",
        "        print(f\"z shape: {z.shape} / C shape: {c.shape}\")\n",
        "        x = torch.cat([z, c], 1)\n",
        "        out = self.model(x)\n",
        "        return out.view(-1, self.smiles_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "_uuid": "0d875fd305440b7572a3100bf4feae72ca57a8a5",
        "collapsed": true,
        "id": "D_DbsSAEq9z3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "generator = Generator(dataset.smiles_nodes, dataset.classes_nodes, dataset.smiles.shape).to(device)\n",
        "discriminator = Discriminator(dataset.smiles_nodes, dataset.classes_nodes, dataset.smiles.shape).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPpI7M_nLGJD",
        "outputId": "db021121-93a8-4638-ef31-cddf1ece91ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z shape: torch.Size([1, 100]) / C shape: torch.Size([1, 68121])\n",
            "X shape: torch.Size([1, 8550]) / C shape: torch.Size([1, 68121])\n"
          ]
        }
      ],
      "source": [
        "# generator = Generator(dataset.smiles_nodes, dataset.classes_nodes, dataset.smiles.shape).to(device)\n",
        "# discriminator = Discriminator(dataset.smiles_nodes, dataset.classes_nodes, dataset.smiles.shape).to(device)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "x_shape = 100\n",
        "y_shape = 261\n",
        "x = random.randint(0, 100, x_shape)\n",
        "y = random.randint(0, 1, y_shape)\n",
        "\n",
        "x = torch.tensor(x).to(device).view(batch_size, -1)\n",
        "y = torch.tensor(y).to(device).view(batch_size, -1)\n",
        "\n",
        "fake_smile = generator(x, y)\n",
        "\n",
        "y_shape = 261\n",
        "y = random.randint(0, 100, y_shape)\n",
        "y = torch.tensor(y).to(device).view(batch_size, -1)\n",
        "\n",
        "out = discriminator(fake_smile, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "_uuid": "2f3f7aa2d3d961df8623b93b3770b88f83bc77d0",
        "collapsed": true,
        "id": "Emc2YsZDq9z3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "_uuid": "b976b9831f73e1d5da270c4050d380f4fe141933",
        "collapsed": true,
        "id": "NcPlds6Xq9z4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad()\n",
        "    z = Variable(torch.randn(batch_size, 100)).to(device)\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, generator.classes_nodes, batch_size))).to(device)\n",
        "    fake_smiles = generator(z, fake_labels)\n",
        "    validity = discriminator(fake_smiles, fake_labels)\n",
        "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "    return g_loss.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "_uuid": "ce7aa31b594067c3e3c006944ca16e7cba2c5ed4",
        "collapsed": true,
        "id": "Z4VUhkOaq9z4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_smiles, labels):\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # train with real smiles\n",
        "\n",
        "    real_validity = discriminator(real_smiles, labels)\n",
        "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
        "\n",
        "    # train with fake smiles\n",
        "    z = Variable(torch.randn(batch_size, 100)).to(device)\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).to(device)\n",
        "\n",
        "    fake_smiles = generator(z, fake_labels)\n",
        "\n",
        "    fake_validity = discriminator(fake_smiles, fake_labels)\n",
        "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).to(device))\n",
        "\n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    return d_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tpxldLCAq9z5"
      },
      "outputs": [],
      "source": [
        "def save_smiles(epoch, sample_smiles):\n",
        "    # Rescale smiles 0 - 1\n",
        "    if not os.path.exists('./smiles'):\n",
        "        os.mkdir('./smiles')\n",
        "\n",
        "    processed_molecules = preprocessing_data(sample_smiles, inverse_dict)\n",
        "\n",
        "    with open('smiles/cgan_%d.txt' % epoch, 'a') as f:\n",
        "        for molecule in processed_molecules:\n",
        "            f.write(molecule)\n",
        "            f.write('\\n')\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "_uuid": "f3c434a2dbc65b30dffa090ba0b51be3588763c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "collapsed": true,
        "id": "MBKbPzgLq9z5",
        "outputId": "6e7c3318-5764-449b-d55b-af6776c1e8d0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 0...\n",
            "X shape: torch.Size([64, 8550]) / C shape: torch.Size([64, 68121])\n",
            "z shape: torch.Size([64, 100]) / C shape: torch.Size([64, 261])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x361 and 68221x1024)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   generator\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   batch_size \u001b[39m=\u001b[39m real_smiles\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   d_loss \u001b[39m=\u001b[39m discriminator_train_step(batch_size, discriminator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                     generator, d_optimizer, criterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                     real_smiles, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   g_loss \u001b[39m=\u001b[39m generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m generator\u001b[39m.\u001b[39meval()\n",
            "\u001b[1;32m/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m z \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mrandn(batch_size, \u001b[39m100\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m fake_labels \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mLongTensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m, batch_size)))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m fake_smiles \u001b[39m=\u001b[39m generator(z, fake_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m fake_validity \u001b[39m=\u001b[39m discriminator(fake_smiles, fake_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m fake_loss \u001b[39m=\u001b[39m criterion(fake_validity, Variable(torch\u001b[39m.\u001b[39mzeros(batch_size))\u001b[39m.\u001b[39mto(device))\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;32m/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mz shape: \u001b[39m\u001b[39m{\u001b[39;00mz\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m / C shape: \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([z, c], \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thiago/Desktop/facul/TCC/EnsembleGAN/src/Copy_of_pytorch_conditional_gan.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmiles_nodes)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x361 and 68221x1024)"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "n_critic = 5\n",
        "display_step = 300\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Starting epoch {}...'.format(epoch))\n",
        "\n",
        "    for i, (smiles, labels) in enumerate(data_loader):\n",
        "      real_smiles = Variable(smiles.to(torch.long)).to(device).squeeze(1)\n",
        "      labels = Variable(labels.to(torch.long)).to(device)\n",
        "\n",
        "      generator.train()\n",
        "      batch_size = real_smiles.size(0)\n",
        "\n",
        "      d_loss = discriminator_train_step(batch_size, discriminator,\n",
        "                                        generator, d_optimizer, criterion,\n",
        "                                        real_smiles, labels)\n",
        "\n",
        "      g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
        "\n",
        "    generator.eval()\n",
        "    print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
        "    z = Variable(torch.randn(9, 100)).cuda()\n",
        "    labels = Variable(torch.LongTensor(np.arange(9))).cuda()\n",
        "    sample_smiles = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    save_smiles(epoch, sample_smiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d87a0e53fb451a6cab5ad07f06d45eb8387644aa",
        "id": "Orq5sZdQq9z6"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "7a143c8f12edf5fbe6e607185215fad39f8b932b",
        "collapsed": true,
        "id": "32bWpfKSq9z6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "z = Variable(torch.randn(100, 100)).cuda()\n",
        "labels = Variable(torch.LongTensor([i for _ in range(10) for i in range(10)])).cuda()\n",
        "sample_smiles = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "grid = make_grid(sample_smiles, nrow=10, normalize=True).permute(1,2,0).numpy()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.imshow(grid)\n",
        "_ = plt.yticks([])\n",
        "_ = plt.xticks(np.arange(15, 300, 30), ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], rotation=45, fontsize=20)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
